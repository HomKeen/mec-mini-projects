{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4445534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import pydicom as dcm\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3f73a6-470f-4d39-9d0e-5b19781d82f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: A100-SXM4-40GB, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f778cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 01:57:31.871655: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-22 01:57:32.410773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31915 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "inception = keras.applications.resnet.ResNet101(include_top=False, input_shape=(512,512,3), weights='imagenet', \n",
    "                                                       classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5bf27e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inception.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_and_width(dicom):\n",
    "    return tuple([int(x[0]) if type(x) == dcm.multival.MultiValue else int(x) for x in [dicom.WindowCenter, dicom.WindowWidth]])\n",
    "def normalize_minmax(img):\n",
    "    mi, ma = img.min(), img.max()\n",
    "    return (img - mi) / (ma - mi)\n",
    "\n",
    "def window_filter(img, center, width, slope, intercept):\n",
    "    out = np.copy(img)\n",
    "    out = out*slope + intercept\n",
    "    lowest_visible = center - width//2\n",
    "    highest_visible = center + width//2\n",
    "    \n",
    "    out[out < lowest_visible] = lowest_visible\n",
    "    out[out > highest_visible] = highest_visible\n",
    "    return normalize_minmax(out)\n",
    "def standardize(img):\n",
    "    m, std = img.mean(), img.std()\n",
    "    return (img - m) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a0339a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(inception)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2e8626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet101 (Functional)      (None, 16, 16, 2048)      42658176  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 12294     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,670,470\n",
      "Trainable params: 42,565,126\n",
      "Non-trainable params: 105,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d280664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "              metrics=['binary_accuracy', \n",
    "                       keras.metrics.AUC(multi_label=True, num_labels=6, from_logits=False),\n",
    "                       keras.metrics.Precision(), keras.metrics.Recall()],\n",
    "             optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(filepath='reproduce_training_2/checkpoint.ckpt',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6024ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tens = tf.convert_to_tensor(data)\n",
    "# model.predict(data_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6251fd22-b047-4484-8edb-bf9069c12e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_img_tensor(img_path):\n",
    "#     dicom = dcm.dcmread(img_path, force=True)\n",
    "    \n",
    "#     img = dicom.pixel_array\n",
    "#     center, width = get_center_and_width(dicom)\n",
    "#     slope, intercept = dicom.RescaleSlope, dicom.RescaleIntercept\n",
    "#     brain = window_filter(img, 40, 80, slope, intercept)\n",
    "#     subdural = window_filter(img, 80, 200, slope, intercept)\n",
    "#     tissue = window_filter(img, 40, 380, slope, intercept)\n",
    "    \n",
    "#     return tf.convert_to_tensor(np.stack([brain, subdural, tissue], axis=2), dtype=tf.dtypes.float32)\n",
    "def get_img_tensor(img_path):\n",
    "    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25f9501c-3d6f-4df0-aae6-394eef3b2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_path = 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/'\n",
    "labels = pd.read_csv('rsna-intracranial-hemorrhage-detection/train_labels.csv')\n",
    "labels = {l[0]: l[1:].astype(np.int8) for l in labels.to_numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01bfbb9a-9098-4275-910a-38d186a02854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNASequence(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = [self.y[img_id.split('/')[-1].split('.')[0]] for img_id in batch_x]\n",
    "        # batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0), \n",
    "               tf.convert_to_tensor(batch_y))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        ind = np.random.choice(list(range(len(os.listdir(png_path)))), size=train_cutoff, replace=False)\n",
    "        self.x = [png_path + img_name for img_name in np.array(os.listdir(png_path))[ind]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02559227-3636-471b-a08a-bb57621ba716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = 25600 #training the whole dataset takes ~9 hours, so we cut it short for proof-of-concept purposes.\n",
    "ind = np.random.choice(list(range(len(os.listdir(png_path)))), size=train_cutoff, replace=False)\n",
    "train_sequence = RSNASequence([png_path + img_name for img_name in np.array(os.listdir(png_path))[ind]], labels, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0bc250-b549-4f70-8b9a-07c80831ff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 01:58:02.308813: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - ETA: 0s - loss: 0.1269 - binary_accuracy: 0.9557 - auc: 0.8826 - precision: 0.7119 - recall: 0.3602\n",
      "Epoch 00001: saving model to reproduce_training_2/checkpoint.ckpt\n",
      "800/800 [==============================] - 1140s 1s/step - loss: 0.1269 - binary_accuracy: 0.9557 - auc: 0.8826 - precision: 0.7119 - recall: 0.3602\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1006 - binary_accuracy: 0.9646 - auc: 0.9219 - precision: 0.7839 - recall: 0.5086\n",
      "Epoch 00002: saving model to reproduce_training_2/checkpoint.ckpt\n",
      "800/800 [==============================] - 1076s 1s/step - loss: 0.1006 - binary_accuracy: 0.9646 - auc: 0.9219 - precision: 0.7839 - recall: 0.5086\n",
      "Epoch 3/3\n",
      "228/800 [=======>......................] - ETA: 12:30 - loss: 0.0971 - binary_accuracy: 0.9669 - auc: 0.9256 - precision: 0.8087 - recall: 0.5583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-22 02:39:38.362445: W tensorflow/core/framework/op_kernel.cc:1733] UNKNOWN: UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 834, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 960, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in __getitem__\n",
      "    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n",
      "\n",
      "  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in <listcomp>\n",
      "    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n",
      "\n",
      "  File \"/tmp/ipykernel_5003/1290730367.py\", line 13, in get_img_tensor\n",
      "    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 3031, in open\n",
      "    \"cannot identify image file %r\" % (filename if filename else fp)\n",
      "\n",
      "PIL.UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) UNKNOWN:  UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 834, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 960, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in __getitem__\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in <listcomp>\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1290730367.py\", line 13, in get_img_tensor\n    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)\n\n  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 3031, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_less_equal/Assert/AssertGuard/else/_1705/assert_less_equal/Assert/AssertGuard/Assert/data_4/_90]]\n  (1) UNKNOWN:  UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 834, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 960, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in __getitem__\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in <listcomp>\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1290730367.py\", line 13, in get_img_tensor\n    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)\n\n  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 3031, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_40842]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5003/1436747763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.predict(train_sequence[1][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_sequence[1][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) UNKNOWN:  UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 834, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 960, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in __getitem__\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in <listcomp>\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1290730367.py\", line 13, in get_img_tensor\n    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)\n\n  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 3031, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[assert_less_equal/Assert/AssertGuard/else/_1705/assert_less_equal/Assert/AssertGuard/Assert/data_4/_90]]\n  (1) UNKNOWN:  UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 834, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\", line 960, in generator_fn\n    yield x[i]\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in __getitem__\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1718398186.py\", line 13, in <listcomp>\n    return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0),\n\n  File \"/tmp/ipykernel_5003/1290730367.py\", line 13, in get_img_tensor\n    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)\n\n  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 3031, in open\n    \"cannot identify image file %r\" % (filename if filename else fp)\n\nPIL.UnidentifiedImageError: cannot identify image file 'rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/ID_5589465c2.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_40842]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_sequence, epochs=3, callbacks=[cp_callback])\n",
    "# model.predict(train_sequence[1][0])\n",
    "# train_sequence[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771b146a-99a6-417a-b54c-f2c1b8b3ac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"reproduce_training_2/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc9b67-a2fd-4324-ba13-a26fe55713d9",
   "metadata": {},
   "source": [
    "We can see that training on just a few thousand of the 700k+ DICOM training images yields a 96% accuracy and an AUC of 0.92 on the training dataset, using ResNet101 pretrained weights as a base and fine tuning using a custom softmax binary cross-entropy layer. These preliminary results are very promising, however it is unknown whether the model can generalize to the entire training set let alone the test set. Additionally, the recall of ~0.5 is rather low, reflecting the highly imbalanced nature of the dataset. However, I believe that I have succeeded in reproducing one part of the research that I have conducted- all solutions I found used a CNN with pretrained weights as the first stage for their model. While reproducing the entirety of their research would take up to a week of coding, debugging, and training (not to mention money); I believe that my results are sufficient for this capstone submission (which predicted a 5-20 hour timeframe). \n",
    "\n",
    "When testing full models, I plan to start by training at least 1 epoch on the full dataset with the CNN, then expirement with feeding the results and the extracted features (taken from the CNN's pennultimate layer) to feed into:\n",
    "1. An ensemble method of boosting or bagging tree methods (as one of my sources did)\n",
    "2. A RNN, perhaps a LSTM\n",
    "3. Another CNN\n",
    "4. An ensemble of RNNs and/or CNNs\n",
    "\n",
    "Such experimentation will take lots of time and I worry that it will bring me above the $300 credit limit alloted to me for Paperspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0247a9c-5311-48c8-9bc8-3acfe1fa88f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
