{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89dc4687-150e-4a87-9572-5d440a84f53a",
   "metadata": {},
   "source": [
    "This notebook will create feature vectors and save each one in a NPY file, by extracting the feature vector after passing a DICOM image through the CNN feature exetractor, which has been pre-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b9a21e-4f94-46fd-8a0f-767cace94ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "from joblib import Parallel, delayed\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35db95d-70ef-4833-9b5d-93e57e71ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: A100-SXM4-40GB, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "feature_dir = '/home/jupyter/extracted-features/' #directory to store all NPY files containing extracted features\n",
    "train_img_dir = '/home/jupyter/rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/' #directory containing all DICOM training images as PNGs\n",
    "extractor_path = '/home/jupyter/base-cnn-model/checkpoint.ckpt/' #directory containing the model of the base CNN feature extractor\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caab5543-aba6-4098-8407-c34934a847f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.models.load_model(extractor_path)\n",
    "extractor = keras.models.Sequential(base_model.layers[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bb38cc-a042-4fc7-956e-8326c0a5575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensor(img_path):\n",
    "    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b354c8f3-440b-4fb3-8d8a-6fa4a321a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_features(img_dir):\n",
    "    \"\"\"\n",
    "    Passes all the images through the extractor model first before training and save them in feature_dir as \n",
    "    feature vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    to_compute = set(x.split('.')[0] for x in os.listdir(train_img_dir))\n",
    "    present = set(x.split('.')[0] for x in os.listdir(feature_dir))\n",
    "\n",
    "    print(f'{len(to_compute.intersection(present))} feature vectors already present')\n",
    "    to_compute = list(to_compute.difference(present))\n",
    "    print(f'Computing {len(to_compute)} new feature vectors...')\n",
    "    compute_batch_size = 200\n",
    "\n",
    "    if len(to_compute) == 0:\n",
    "        return\n",
    "\n",
    "    for i in tqdm(range(ceil(len(to_compute)//compute_batch_size)+1)):\n",
    "        batch_names = to_compute[i*compute_batch_size : (i+1)*compute_batch_size]\n",
    "        batch = np.array(Parallel(n_jobs=-1, backend='threading')(delayed(get_img_tensor)(img_dir+img_id+'.png') for img_id in batch_names if img_id))\n",
    "        try:\n",
    "            batch = extractor.predict(batch)\n",
    "        except:\n",
    "            print(\"ERROR\")\n",
    "            print(batch.shape)\n",
    "            \n",
    "        for i,feat_vec in enumerate(batch):\n",
    "            np.save(feature_dir+batch_names[i]+'.npy', feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ed93f0-d63f-4a67-ab2b-6416c5489338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752521 feature vectors already present\n",
      "Computing 1 new feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "(0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "precompute_features(train_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fdd9c-9364-4b07-860b-ef312886308c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
