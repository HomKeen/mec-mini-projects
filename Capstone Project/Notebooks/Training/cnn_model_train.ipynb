{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c75ff1d-d13a-41ce-9a17-015bfccccfb8",
   "metadata": {},
   "source": [
    "This notebook is for fine-tuning TensorFlow's ResNet101 model to predict the class of a single slice of a CT scan. Its results are not expected to be acceptable, but will serve as a feature extractor and input for another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4445534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import pydicom as dcm\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f73a6-470f-4d39-9d0e-5b19781d82f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9501c-3d6f-4df0-aae6-394eef3b2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_path = '/home/jupyter/rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/'\n",
    "label_path = '/home/jupyter/rsna-intracranial-hemorrhage-detection/train_labels.csv'\n",
    "\n",
    "batch_size = 32 \n",
    "#Training the whole dataset takes ~9 hours, so we cut it short. Set this to -1 to train on the whole dataset\n",
    "#Before each epoch, we randomly select (without replacement) from the whole training dataset.\n",
    "max_num_batches = 1200 \n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41e5e1-9191-4174-adfd-437dd0d59ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(label_path)\n",
    "labels = {l[0]: l[1:].astype(np.int8) for l in labels.to_numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f778cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the pretrained model\n",
    "inception = keras.applications.resnet.ResNet101(include_top=False, input_shape=(512,512,3), weights='imagenet', \n",
    "                                                       classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inception.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_and_width(dicom):\n",
    "    return tuple([int(x[0]) if type(x) == dcm.multival.MultiValue else int(x) for x in [dicom.WindowCenter, dicom.WindowWidth]])\n",
    "def normalize_minmax(img):\n",
    "    mi, ma = img.min(), img.max()\n",
    "    return (img - mi) / (ma - mi)\n",
    "\n",
    "def window_filter(img, center, width, slope, intercept):\n",
    "    out = np.copy(img)\n",
    "    out = out*slope + intercept\n",
    "    lowest_visible = center - width//2\n",
    "    highest_visible = center + width//2\n",
    "    \n",
    "    out[out < lowest_visible] = lowest_visible\n",
    "    out[out > highest_visible] = highest_visible\n",
    "    return normalize_minmax(out)\n",
    "def standardize(img):\n",
    "    m, std = img.mean(), img.std()\n",
    "    return (img - m) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0339a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(inception)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "              metrics=['binary_accuracy', \n",
    "                       keras.metrics.AUC(multi_label=True, num_labels=6, from_logits=False),\n",
    "                       keras.metrics.Precision(), keras.metrics.Recall()],\n",
    "             optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(filepath='reproduce_training_2/checkpoint.ckpt',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251fd22-b047-4484-8edb-bf9069c12e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensor(img_path):\n",
    "    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bfbb9a-9098-4275-910a-38d186a02854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNASequence(keras.utils.Sequence):\n",
    "    def __init__(self, all_x, labels, img_dir, batch_size):\n",
    "        \"\"\"\n",
    "        \n",
    "        :all_x (list of str): list of image file names of each training vector (as a PNG) in the entire dataset\n",
    "        :labels (dict): maps DICOM image IDs (str) to 1D np.array of bool of length 6, representing the label of each training image\n",
    "        :img_dir (str): absolute directory containing the PNG images of each training image.\n",
    "        :batch_size (int): number of training images to include in a single batch\n",
    "        \"\"\"\n",
    "        self.x = all_x\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end() #compute the first set of training batches\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = [self.labels[img_id] for img_id in batch_x]\n",
    "        \n",
    "        return (tf.stack([get_img_tensor(self.img_dir+img_path+'.png') for img_path in batch_x], axis=0), \n",
    "               tf.convert_to_tensor(batch_y))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        ind = np.random.choice(list(range(len(os.listdir(self.img_dir)))), size=train_cutoff, replace=False)\n",
    "        self.x = [img_name.split('.')[0] for img_name in np.array(os.listdir(self.img_dir))[ind]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02559227-3636-471b-a08a-bb57621ba716",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_vec = len(os.listdir(png_path))\n",
    "train_cutoff = batch_size*max_num_batches if max_num_batches >= 0 else total_train_vec #number of data vectors to train on\n",
    "\n",
    "ind = np.random.choice(list(range(total_train_vec)), size=train_cutoff, replace=False)\n",
    "train_sequence = RSNASequence(np.array(os.listdir(png_path))[ind], labels, png_path, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bc250-b549-4f70-8b9a-07c80831ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_sequence, epochs=n_epochs, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b146a-99a6-417a-b54c-f2c1b8b3ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"reproduce_training_2/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc9b67-a2fd-4324-ba13-a26fe55713d9",
   "metadata": {},
   "source": [
    "We can see that training on just a few thousand of the 700k+ DICOM training images yields a 96% accuracy and an AUC of 0.92 on the training dataset, using ResNet101 pretrained weights as a base and fine tuning using a custom softmax binary cross-entropy layer. These preliminary results are very promising, however it is unknown whether the model can generalize to the entire training set let alone the test set. Additionally, the recall of ~0.5 is rather low, reflecting the highly imbalanced nature of the dataset. However, I believe that I have succeeded in reproducing one part of the research that I have conducted- all solutions I found used a CNN with pretrained weights as the first stage for their model. While reproducing the entirety of their research would take up to a week of coding, debugging, and training (not to mention money); I believe that my results are sufficient for this capstone submission (which predicted a 5-20 hour timeframe). \n",
    "\n",
    "When testing full models, I plan to start by training at least 1 epoch on the full dataset with the CNN, then expirement with feeding the results and the extracted features (taken from the CNN's pennultimate layer) to feed into:\n",
    "1. An ensemble method of boosting or bagging tree methods (as one of my sources did)\n",
    "2. A RNN, perhaps a LSTM\n",
    "3. Another CNN\n",
    "4. An ensemble of RNNs and/or CNNs\n",
    "\n",
    "Such experimentation will take lots of time and I worry that it will bring me above the $300 credit limit alloted to me for Paperspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0247a9c-5311-48c8-9bc8-3acfe1fa88f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
