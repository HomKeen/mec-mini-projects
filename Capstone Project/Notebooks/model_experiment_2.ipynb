{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e7babd-8fbf-40bd-8536-557e68ed5ca1",
   "metadata": {},
   "source": [
    "This notebook is for experimenting with a CNN to PCA to RNN LSTM network model. The CNN will first have its dimensions reduced by PCA, then the LSTM network train on one CT scan at a time; it will take in the principal components of each slice in a scan and output predictions for ICH on each slice, while taking into account spacial dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a336d01d-da5b-4276-a992-1e47d552549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1708fad-9774-473d-abb1-99016de5ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: A100-SXM4-40GB, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "train_img_dir = '/home/jupyter/rsna-intracranial-hemorrhage-detection/stage_2_train_imgs/'\n",
    "train_label_path = '/home/jupyter/rsna-intracranial-hemorrhage-detection/train_labels.csv'\n",
    "train_ct_path = '/home/jupyter/rsna-intracranial-hemorrhage-detection/train_ct_scans.csv'\n",
    "train_coord_path = '/home/jupyter/rsna-intracranial-hemorrhage-detection/train_ct_coords.csv'\n",
    "\n",
    "test_img_dir = '/home/jupyter/rsna-intracranial-hemorrhage-detection/stage_2_test_imgs/'\n",
    "\n",
    "keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222da51a-fd64-4024-88ce-fd3ff8aacec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 06:36:55.159535: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-23 06:36:55.693965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38444 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet101 (Functional)      (None, 16, 16, 2048)      42658176  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,658,176\n",
      "Trainable params: 42,552,832\n",
      "Non-trainable params: 105,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.models.load_model('/home/jupyter/reproduce_training_2/checkpoint.ckpt')\n",
    "extractor = keras.models.Sequential(base_model.layers[:-1])\n",
    "extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834fca5b-3842-48d8-9202-ceb6d6c95f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensor(img_path):\n",
    "    return tf.convert_to_tensor(np.asarray(Image.open(img_path), dtype=np.float32) / 255.)\n",
    "\n",
    "\n",
    "class RSNASequence(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x = x_set\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = [self.y[img_id.split('/')[-1].split('.')[0]] for img_id in batch_x]\n",
    "        \n",
    "        return (tf.stack([get_img_tensor(img_path) for img_path in batch_x], axis=0), \n",
    "               tf.convert_to_tensor(batch_y))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        ind = np.random.choice(list(range(len(os.listdir(train_img_dir)))), size=train_cutoff, replace=False)\n",
    "        self.x = [train_img_dir + img_name for img_name in np.array(os.listdir(train_img_dir))[ind]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891dd84f-c41f-4776-8c7a-518244ca3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(train_label_path)\n",
    "labels = {l[0]: l[1:].astype(np.int8) for l in labels.to_numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64f83f7-a9ca-440d-9489-6ba99223d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_cutoff = batch_size * 4000 #training the whole dataset takes ~9 hours, so we cut it short for proof-of-concept purposes.\n",
    "ind = np.random.choice(list(range(len(os.listdir(train_img_dir)))), size=train_cutoff, replace=False)\n",
    "train_sequence = RSNASequence([train_img_dir + img_name for img_name in np.array(os.listdir(train_img_dir))[ind]], labels, batch_size)\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(filepath='/home/jupyter/reproduce_training_2/checkpoint.ckpt',\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0906e3-49fe-4994-b2d5-e3e5fc5cebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 06:37:56.076647: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 0s - loss: 0.0751 - binary_accuracy: 0.9733 - auc: 0.9613 - precision: 0.8410 - recall: 0.6575\n",
      "Epoch 00001: saving model to /home/jupyter/reproduce_training_2/checkpoint.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 07:30:29.796167: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jupyter/reproduce_training_2/checkpoint.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 3213s 797ms/step - loss: 0.0751 - binary_accuracy: 0.9733 - auc: 0.9613 - precision: 0.8410 - recall: 0.6575\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 0.0708 - binary_accuracy: 0.9749 - auc: 0.9646 - precision: 0.8475 - recall: 0.6763\n",
      "Epoch 00002: saving model to /home/jupyter/reproduce_training_2/checkpoint.ckpt\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/reproduce_training_2/checkpoint.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2944s 736ms/step - loss: 0.0708 - binary_accuracy: 0.9749 - auc: 0.9646 - precision: 0.8475 - recall: 0.6763\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - ETA: 0s - loss: 0.0676 - binary_accuracy: 0.9759 - auc: 0.9684 - precision: 0.8521 - recall: 0.6936\n",
      "Epoch 00003: saving model to /home/jupyter/reproduce_training_2/checkpoint.ckpt\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/reproduce_training_2/checkpoint.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2754s 689ms/step - loss: 0.0676 - binary_accuracy: 0.9759 - auc: 0.9684 - precision: 0.8521 - recall: 0.6936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f571da048d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(x=train_sequence, epochs=3, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc37ee-0321-48c9-b75a-9a8106c1628e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19bdd3-71f7-4b9a-8d85-5993f238e72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
